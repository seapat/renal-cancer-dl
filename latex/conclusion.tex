\chapter{Conclusion} 
    \label{conclusion}

Before the more drastic steps discussed in Chapter \ref{Discussion} are taken, some more straightforward changes to the architecture are in order. Apart from the already discussed optimisation of hyperparameters, there would be the implementation of learning rate scheduling. We showed for both unimodal networks that adjustments of the learning rate can severely alter the performance of the networks. Therefore, by altering the learning rate respective to the time passed during training, we could observe significant differences both in terms of speed of convergence and the predictive performance of the model obtained. Although, the Adam optimiser already performs weight decay, the authors of the AdamW modifications also consider such a schedule to be worthwhile addition. \cite{Loshchilov2017Decoupled}

Another aspect that can easily explored is the following. One could argue that we perform in fact two types of fusion. If we consider the binary masks created from the annotations as separate, we are first performing early fusion by combining them with the WSIs and the addition of gene expression data can be considered intermediate fusion. Therefore, it would be interesting to investigate the behaviour of the network if, the masks are excluded, either completely or via some dropout mechanism. Since we noticed in our analysis of feature attributions, that the network relies heavily on the presence of these masks, a partial removal might force the network to consider other features in the data more strongly. As it stands right now, it is questionable if our findings are truly novel or if the revealed tissue areas were already known to be important. 

When considering the poor results from the analysis of the gene expression data, it is very likely that the provided 24 samples were simply too few for proper use in a deep neural network. Since we show that we were able to fit a simple linear regression model, the more suitable approach would have been a late fusion-based one, where the WSI data are processed by a neural net and the genomic data by a much simpler model. Only the respective independent predictions are pooled afterwards. This would have greatly simplified the availability problem of genomic data, as in cases where this data was missing, the results of the neural network could have been accepted directly.
However, because this work was supposed to be an “innovative big data approach integrating spatially derived and molecular data” (cited from the DigistrucMed project proposal), such an approach was not within the scope of the project. After all, if we had more data available, our approach might work much better, as is often the case with deep learning models.
It is the authors' observation that too often researches blindly call for big data approaches and thus confidently ignore any rationality. Meanwhile, they are being misguided by their greed for doing something fancy instead of something effective.

Generally, the performance of the CNN is quite satisfactory, especially when considering the quality issues the dataset has. We believe that especially the novel treatment of tissue annotations is a worthwhile contribution to the state of the art that should be explored further in the future. 

